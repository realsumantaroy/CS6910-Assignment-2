{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 8029718,
          "sourceType": "datasetVersion",
          "datasetId": 4732746
        }
      ],
      "dockerImageVersionId": 30674,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "sc6910 RAW Code Part A",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Part B Question 3"
      ],
      "metadata": {
        "id": "hLGaLEVmjcdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "batch_size=32\n",
        "num_epochs=5\n",
        "learning_rate=1e-3\n",
        "\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Freezing all layers except the final layer\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replacing the final fully connected layer with a new one for 10 classes\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 10)  # Changing 10 to the number of classes in my dataset\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "vanilla_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Loading the dataset\n",
        "dataset = ImageFolder('/kaggle/input/dataset/inaturalist_12K/train', transform=train_transform)\n",
        "train_indices, val_indices = train_test_split(range(len(dataset)), test_size=0.2, shuffle=True, stratify=dataset.targets)\n",
        "train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_indices)\n",
        "val_sampler = torch.utils.data.sampler.SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)\n",
        "\n",
        "test_dataset = ImageFolder('/kaggle/input/dataset/inaturalist_12K/val', transform=vanilla_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-06T17:42:02.729576Z",
          "iopub.execute_input": "2024-04-06T17:42:02.730471Z",
          "iopub.status.idle": "2024-04-06T17:42:04.911075Z",
          "shell.execute_reply.started": "2024-04-06T17:42:02.730436Z",
          "shell.execute_reply": "2024-04-06T17:42:04.910306Z"
        },
        "trusted": true,
        "id": "CxbzEim8jcdr",
        "outputId": "ea542132-a992-475d-bfdf-0c197d8aacfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "if torch.cuda.is_available():\n",
        "    model=model.cuda()\n",
        "    criterion=criterion.cuda()\n",
        "\n",
        "n_total_steps = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Setting model to training mode\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        train_loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimizer\n",
        "        optimizer.zero_grad()\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'At end of epoch [{epoch+1}/{num_epochs}], training loss: {train_loss.item():.4f}')\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "            outputs = model(images)\n",
        "            val_loss = criterion(outputs, labels)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_accuracy = 100 * correct / total\n",
        "    print(f'At end of epoch [{epoch+1}/{num_epochs}], validation loss: {val_loss.item():.4f}, validation acuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "\n",
        "print('Finished Training')\n",
        "# Test phase\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        outputs = model(images)\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "test_accuracy = 100 * correct / total\n",
        "print(f'Test accuracy: {test_accuracy:.2f}%')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-06T17:42:36.261186Z",
          "iopub.execute_input": "2024-04-06T17:42:36.261976Z",
          "iopub.status.idle": "2024-04-06T17:53:49.219396Z",
          "shell.execute_reply.started": "2024-04-06T17:42:36.261944Z",
          "shell.execute_reply": "2024-04-06T17:53:49.218274Z"
        },
        "trusted": true,
        "id": "GmK1CbzWjcds",
        "outputId": "0510d5d7-de82-4ff8-b198-f3ea61afab94"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "At end of epoch [1/5], training loss: 1.2658\nAt end of epoch [1/5], validation loss: 0.9687, validation acuracy: 73.00%\nAt end of epoch [2/5], training loss: 0.9591\nAt end of epoch [2/5], validation loss: 1.1460, validation acuracy: 74.05%\nAt end of epoch [3/5], training loss: 1.1457\nAt end of epoch [3/5], validation loss: 0.3460, validation acuracy: 72.25%\nAt end of epoch [4/5], training loss: 0.9737\nAt end of epoch [4/5], validation loss: 0.7586, validation acuracy: 71.30%\nAt end of epoch [5/5], training loss: 0.5944\nAt end of epoch [5/5], validation loss: 1.0563, validation acuracy: 73.65%\nFinished Training\nTest accuracy: 74.25%\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}